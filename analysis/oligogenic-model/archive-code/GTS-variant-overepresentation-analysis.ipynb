{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "\n",
    "# This line will hide code by default when the notebook is exported as HTML\n",
    "# di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/venv-hail-0.2.105/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-12 10:12:03.544 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.1.3\n",
      "SparkUI available at http://ac0079:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.105-acd89e80c345\n",
      "LOGGING: writing to /net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/analysis/oligogenic-model/hail-20230112-1012-0.2.105-acd89e80c345.log\n"
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "hl.init(\n",
    "    tmp_dir='/net/ascratch/people/plggosborcz/gosborcz-hail',\n",
    "    spark_conf={'spark.driver.memory': '30G', 'spark.executor.memory': '30G'},\n",
    "    default_reference='GRCh38') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hail.plot import show\n",
    "from pprint import pprint\n",
    "from bokeh.layouts import gridplot\n",
    "hl.plot.output_notebook()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import statistics as stat\n",
    "from collections import Counter\n",
    "    \n",
    "import bokeh.palettes\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### important note: file paths in this notebook are outdated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SKAT functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sex_chrom(mtx):\n",
    "    mtx = mtx.filter_rows(mtx.locus.contig != \"chrY\")\n",
    "    return(mtx)\n",
    "\n",
    "\n",
    "def run_pca(mtx, mtx_subset):\n",
    "    eigenvalues, pcs, _ = hl.hwe_normalized_pca(mtx_subset.GT)\n",
    "    mtx = mtx.annotate_cols(scores = pcs[mtx.s].scores)\n",
    "\n",
    "    return(mtx)\n",
    "\n",
    "def run_skat_log(mtx, gene_list, pcs):\n",
    "    \n",
    "    mtx = mtx.filter_rows(hl.any(lambda x: hl.literal(gene_list).contains(x), mtx.nearest_genes_20kb))\n",
    "    mtx = mtx.filter_rows(hl.agg.any(mtx.GT.is_non_ref()))\n",
    "    mtx = mtx.explode_rows(mtx.nearest_genes_20kb)\n",
    "    mtx = mtx.filter_rows(hl.literal(gene_list).contains(mtx.nearest_genes_20kb))\n",
    "    \n",
    "    \n",
    "    scores = [mtx.scores[x] for x in list(range(pcs))]\n",
    "                          \n",
    "    \n",
    "    skat_table = hl.skat(\n",
    "                         key_expr=mtx.nearest_genes_20kb,\n",
    "                         weight_expr=mtx.cadd,\n",
    "                         y=mtx.category,\n",
    "                         x=mtx.GT.n_alt_alleles(),\n",
    "                         covariates=[1] + scores,\n",
    "                         max_size = 2500,\n",
    "                         logistic = True)\n",
    "    \n",
    "    genes_result = skat_table.filter(skat_table.p_value < 0.05/len(gene_list)).id.collect() \n",
    "\n",
    "    skat_table.filter(skat_table.p_value < 0.002).show(20)\n",
    "\n",
    "    skat_table = skat_table.annotate(label = hl.literal(genes).contains(skat_table.id))\n",
    "\n",
    "    qq_plot = hl.plot.qq(skat_table.p_value,\n",
    "                                         label = skat_table.label,\n",
    "                                         n_divisions = len(gene_list))\n",
    "    show(qq_plot)\n",
    "    \n",
    "    return(skat_table, genes_result, qq_plot)\n",
    "\n",
    "\n",
    "def full_skat_log(mtx, mtx_subset, gene_list, pcs):\n",
    "    \n",
    "    mtx = remove_sex_chrom(mtx)\n",
    "    mtx_subset = remove_sex_chrom(mtx_subset)\n",
    "  \n",
    "    mtx = run_pca(mtx, mtx_subset) #this matrix will be returned, so I can do SKAT with other list and parameters\n",
    "    skat_table, genes_result, qq_plot = run_skat_log(mtx, gene_list, pcs)\n",
    "    \n",
    "    return(mtx, skat_table, genes_result, qq_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(geneset_name):  \n",
    "    for c_idx, c in enumerate(cadds):\n",
    "\n",
    "        test_asignment = np.zeros((len(top_genes), 145)) \n",
    "        mt_skat_log = hl.read_matrix_table(\n",
    "            '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt_for_skat_'+str(c)+'.mt'\n",
    "        )\n",
    "        mt_test_skat_log = hl.read_matrix_table(\n",
    "            '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt_test_'+str(c)+'.mt'\n",
    "        )\n",
    "      \n",
    "        for rows, n in enumerate(top_genes):\n",
    "\n",
    "            mt_skat_log_gene = mt_skat_log.filter_rows(mt_skat_log.nearest_genes_20kb.contains(n)) # to ma gnomadów i heavy tics\n",
    "        \n",
    "            mt_test_skat_log_gene = mt_test_skat_log.filter_rows(mt_test_skat_log.nearest_genes_20kb.contains(n)) # to ma rodziny\n",
    "\n",
    "            mt_skat_log_gene = mt_skat_log_gene.annotate_cols(non_refs = hl.agg.count_where(mt_skat_log_gene.GT.is_non_ref())) #count variants per sample of gnomads and heavy tics  \n",
    "            non_refs = mt_skat_log_gene.non_refs.collect()\n",
    "                                                \n",
    "            mt_test_skat_log_gene = mt_test_skat_log_gene.annotate_cols(non_refs = hl.agg.count_where(mt_test_skat_log_gene.GT.is_non_ref())) #count variants per sample, prepare also test matrix\n",
    "            non_refs_test = mt_test_skat_log_gene.non_refs.collect()\n",
    "\n",
    "            variants_controls = np.mean(np.array(non_refs)[np.invert(categories)])\n",
    "                \n",
    "            test_asignment[rows] = (non_refs_test - variants_controls)\n",
    "            \n",
    "            print(test_asignment.shape)\n",
    "                \n",
    "        for s in sets:\n",
    "        \n",
    "            test_asignment_subset = test_asignment[range(5-s,5), :]\n",
    "            \n",
    "            print(test_asignment_subset.shape)\n",
    "                \n",
    "            test_asignment_subset = np.sum(test_asignment_subset, axis = 0)\n",
    "                \n",
    "            false_pos = []\n",
    "            true_pos = []\n",
    "            \n",
    "            for x in np.linspace(-100,100,10000):\n",
    "            \n",
    "                false_pos.append(np.sum((test_asignment_subset > x)[np.invert(categories_test)])/53)\n",
    "                true_pos.append(np.sum((test_asignment_subset > x)[categories_test])/91)\n",
    "            \n",
    "            print(np.trapz(false_pos, true_pos))\n",
    "        \n",
    "            np.save('/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/oligogenic-auc/false_pos'+str(s)+'cadd'+str(c)+'gene'+geneset_name, false_pos)\n",
    "            np.save('/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/oligogenic-auc/true_pos'+str(s)+'cadd'+str(c)+'gene'+geneset_name, true_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model(gene_list, geneset_name, mt_for_model):\n",
    "    \n",
    "    skat_table, genes_result, qq_plot = run_skat_log(mt_for_model, gene_list, 8)\n",
    "    top_genes = skat_table.order_by('p_value').id.take(5)\n",
    "    test_model(geneset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKAT overrepresentation analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 10:18:40.572 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'Gene stable ID' as type str (not specified)\n",
      "  Loading field 'UniProtKB Gene Name symbol' as type str (not specified)\n"
     ]
    }
   ],
   "source": [
    "genes = ['DCC', 'RBFOX', 'SLC30A9', 'DCAF4L1', 'SORCS3', 'KCNQ5', 'KCNQ-IT1', 'APOPT1', 'C14orf2', 'NAA11', 'NEGR1',\n",
    "        'CHADL', 'SOX5', 'PANK2', 'COL27A1', 'PDGFB', 'CELSR3', 'OPA1', 'FBN2', 'WWC1', 'NIPBL', \n",
    "             'FN1', 'FBN2', 'SLITRK1', 'SLITRK2', 'SLITRK3', 'SLITRK4', 'SLITRK5', 'SLITRK6', \n",
    "             'HDC', 'OPRK1', 'PCDH10', 'NTSR2', 'CHD8', 'SCUBE1', 'PNKD', 'CNTNAP2', 'MOG', \n",
    "             'DRD2', 'DRD3', 'DRD4', 'DRD5', 'DAT1', 'DBH', 'HTR2A', 'TPH2', 'EAAT1', 'SAPAP3',\n",
    "            'CTNNA3', 'NLGN4', 'FSCB', 'IMMP2L', 'NRXN1', 'AADAC', 'DBH', 'MAOA', 'HTR1A', 'HTR2C', 'SLC6A4',\n",
    "             'TPH2', 'COL27A1', '5-HTTLPR', 'EAAT1', 'COL8A1', 'KCNE1', 'KCNE2',\n",
    "         'RICTOR', 'WWC1', 'CELSR3, NIPBL', 'FN1', 'PNKD', 'CDH26', 'CADM2', 'OPCML', 'CDH9',\n",
    "         'NCAM2', 'CD47', 'CDH5', 'CADM4', 'C1QBP', 'CTTN', 'LSAMP',\n",
    "         'PKP4', 'PCDH1', 'CNTNAP2', 'MBP', 'GABBR2', 'GABBR2', 'GRIK4', 'NCR1', 'FLT3', 'IL12A', 'HDAC9',\n",
    "         'CD180', 'CDH26', 'NCAM2', 'NTM', 'ROBO2'] # the other gene next to chadl - 'L3MBTL2' was deleted not to confuse the analysis\n",
    "\n",
    "allgenes = hl.import_table('/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/external-data/gts-gene-lists/human-genes-with-GO-and-symbols') \n",
    "allgenes = allgenes.select('UniProtKB Gene Name symbol')\n",
    "\n",
    "allgenes = allgenes.filter(allgenes['UniProtKB Gene Name symbol'] != \"\")\n",
    "allgenes = allgenes['UniProtKB Gene Name symbol'].collect()\n",
    "\n",
    "genes_scores = list(set(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/GTS-gnomad-sex.mt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now annotate with new phenotypes (update from the clinician)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 10:29:55.000 Hail: INFO: Reading table to impute column types\n",
      "2023-01-12 10:29:55.255 Hail: INFO: Finished type imputation\n",
      "  Loading field 'ID' as type str (imputed)\n",
      "  Loading field 'family' as type str (imputed)\n",
      "  Loading field 'sex' as type str (imputed)\n",
      "  Loading field 'kinship' as type str (imputed)\n",
      "  Loading field 'disease' as type str (imputed)\n",
      "  Loading field 'phenotype' as type str (imputed)\n",
      "  Loading field 'add_pheno' as type str (imputed)\n",
      "  Loading field 'heavy_tics' as type str (imputed)\n",
      "  Loading field 'heavy_tics_familial' as type str (imputed)\n",
      "  Loading field 'GTS_ASD_group' as type str (imputed)\n",
      "  Loading field 'nonCTD' as type str (imputed)\n",
      "2023-01-12 10:32:04.246 Hail: INFO: wrote matrix table with 6437977 rows and 80 columns in 246 partitions to /net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat.mt\n"
     ]
    }
   ],
   "source": [
    "pheno = hl.import_table(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/pheno/GTS-coded-corrected-june-2021.csv',\n",
    "    impute=True,\n",
    "    delimiter=',',\n",
    "    quote=\"\\\"\"\n",
    ")\n",
    "\n",
    "pheno = pheno.key_by(pheno.ID)\n",
    "\n",
    "mt = mt.annotate_cols(phenotypes = pheno[mt.s])\n",
    "mt = mt.filter_cols(mt.s.contains('gnomad') | (mt.phenotypes.family == '.'))\n",
    "mt = mt.annotate_cols(\n",
    "    category = hl.if_else(mt.s.contains('gnomad'),\n",
    "                          False,\n",
    "                          (mt.phenotypes.heavy_tics == 'YES')\n",
    "                         )\n",
    ")\n",
    "\n",
    "samples = mt.s.collect()\n",
    "\n",
    "#first 70 gnomad samples are females (see GTS-annotate-cadd-genes)\n",
    "gnomad_females = samples[40:(40+70)]\n",
    "mt = mt.transmute_cols(\n",
    "    phenotypes = mt.phenotypes.annotate(\n",
    "        sex = hl.if_else(mt.s.contains('gnomad'),\n",
    "                         hl.if_else(\n",
    "                             hl.array(gnomad_females).contains(mt.s),\n",
    "                             'F',\n",
    "                             'M'),\n",
    "                         mt.phenotypes['sex'])\n",
    "    )\n",
    ")\n",
    "\n",
    "sexes = mt.phenotypes.sex.collect()\n",
    "\n",
    "to_keep = samples[0:40] + samples[40:(40+6)] + samples[40+71:40+71+34] #this first 6 gnomad females + first 33 males\n",
    "mt = mt.filter_cols(hl.array(to_keep).contains(mt.s)) # filter out excessive gnomads\n",
    "mt = mt.filter_rows(mt.cadd > 0) # this is so I don't do too many tests\n",
    "mt = mt.naive_coalesce(250)\n",
    "\n",
    "mt.write(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat.mt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now make a subset (same genotypes as previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 10:32:12.468 Hail: INFO: wrote matrix table with 13003 rows and 80 columns in 50 partitions to /net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat-subset.mt\n",
      "    Total size: 6.65 MiB\n",
      "    * Rows/entries: 6.65 MiB\n",
      "    * Columns: 653.00 B\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 120 rows (52.12 KiB)\n",
      "    * Largest partition:  286 rows (186.35 KiB)\n"
     ]
    }
   ],
   "source": [
    "mt_for_skat = hl.read_matrix_table('/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat.mt')\n",
    "mt_subset = mt_for_skat.sample_rows(0.002)\n",
    "mt_subset = mt_subset.naive_coalesce(50)\n",
    "mt_subset.write('/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat-subset.mt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run SKAT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_for_skat = hl.read_matrix_table(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat.mt'\n",
    ")\n",
    "mt_subset = hl.read_matrix_table(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/mt-for-skat-subset.mt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = mt_for_skat.phenotypes.heavy_tics.collect()\n",
    "b = mt_for_skat.phenotypes.add_pheno.collect()\n",
    "c = mt_for_skat.phenotypes.disease.collect()\n",
    "\n",
    "mt_for_model, skat_table_log, genes_result_log, qq_plot_log = full_skat_log(mt_for_skat, mt_subset, genes_scores, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare matrix table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skat_table_log.write('/net/archive/groups/plggneuromol/GTS-analysis/data/skat-expanded-may.ht')\n",
    "mt_for_model.write('/net/archive/groups/plggneuromol/GTS-analysis/data/mt-for-model-expanded-may.mt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the number of variants in control individuals for the classifier\n",
    "\n",
    "A few iterations over various numbers of genes and CADD score cutt-offs were run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skat = hl.read_table('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/data/mts/skat-expanded-may.ht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = hl.plot.qq(skat.p_value)\n",
    "\n",
    "plot.xaxis.axis_label_text_font_size = \"15pt\"\n",
    "plot.xaxis.major_label_text_font_size = \"15pt\"\n",
    "plot.yaxis.axis_label_text_font_size = \"15pt\"\n",
    "plot.yaxis.major_label_text_font_size = \"15pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skat.order_by('p_value').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reimport the matrixtable again and prepare the test dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### reimport the phenotype table again as annotation of WGS_188a has been corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_test = hl.read_matrix_table('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/data/mts/GTS-gnomad-sex.mt')\n",
    "\n",
    "pheno = hl.import_table(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/pheno/GTS-coded-corrected-june-2021.csv',\n",
    "    impute=True,\n",
    "    delimiter=',',\n",
    "    quote=\"\\\"\"\n",
    ")\n",
    "\n",
    "pheno = pheno.key_by(pheno.ID)\n",
    "\n",
    "mt_test = mt_test.annotate_cols(phenotypes = pheno[mt_test.s])\n",
    "\n",
    "mt_test = mt_test.annotate_cols(category = hl.if_else(mt_test.s.contains('gnomad'), False, (mt_test.phenotypes.disease == 'YES')))\n",
    "\n",
    "mt_test = mt_test.filter_cols(mt_test.phenotypes.family == '.', keep = False)\n",
    "mt_test = mt_test.filter_cols((mt_test.phenotypes.disease == 'YES') | (mt_test.phenotypes.disease == 'NO'))\n",
    "\n",
    "mt_test = mt_test.filter_rows(mt_test.cadd > 0) \n",
    "\n",
    "#mt_test.write('/net/archive/groups/plggneuromol/GTS-analysis/data/mt-test-may.mt')\n",
    "mt_for_skat = hl.read_matrix_table('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/data/mts/mt-for-skat-may.mt')\n",
    "mt_test = hl.read_matrix_table('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/data/mts/mt-test-may.mt')\n",
    "skat = hl.read_table('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/data/mts/skat-expanded-may.ht')\n",
    "\n",
    "categories = mt_for_skat.category.collect()\n",
    "categories_test = mt_test.category.collect()\n",
    "\n",
    "np.where(np.array(categories_test) == True)[0].shape\n",
    "np.where(np.array(categories_test) == False)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the test dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to calculate confusion matrix values\n",
    "\n",
    "sum(asignment[np.invert(categories)]) #number of false positives\n",
    "\n",
    "sum(np.invert(asignment)[categories]) # number of false negatives\n",
    "        \n",
    "sum(np.invert(asignment)[np.invert(categories)]) #number of true negatives\n",
    "\n",
    "sum(asignment[categories]) #number of true positives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [2,3,4,5]\n",
    "cadds = [5,10,15,20]\n",
    "\n",
    "for s in sets:\n",
    "    \n",
    "    top_genes = skat.order_by('p_value').id.take(s)   \n",
    "   \n",
    "    for c in cadds:\n",
    "        \n",
    "        variants_controls = np.zeros((len(top_genes)))\n",
    "        variants_gts = np.zeros((len(top_genes)))\n",
    "    \n",
    "        variants_controls_test = np.zeros((len(top_genes)))\n",
    "        variants_gts_test = np.zeros((len(top_genes)))\n",
    "\n",
    "        model_asignment = np.zeros((len(top_genes), 80))\n",
    "        test_asignment = np.zeros((len(top_genes), 145)) \n",
    "    \n",
    "        for rows, n in enumerate(top_genes):\n",
    "            \n",
    "            mt_skat_log = mt_for_skat.filter_rows(mt_for_skat.nearest_genes_20kb.contains(n)) # to ma gnomadów i heavy tics\n",
    "            mt_test_skat_log = mt_test.filter_rows(mt_test.nearest_genes_20kb.contains(n)) # to ma rodziny\n",
    "\n",
    "            mt_skat_log = mt_skat_log.filter_rows(mt_skat_log.cadd > c)\n",
    "            mt_skat_log = mt_skat_log.annotate_cols(non_refs = hl.agg.count_where(mt_skat_log.GT.is_non_ref())) #count variants per sample of gnomads and heavy tics  \n",
    "            non_refs = mt_skat_log.non_refs.collect()\n",
    "\n",
    "            mt_test_skat_log = mt_test_skat_log.filter_rows(mt_test_skat_log.cadd > c)\n",
    "            mt_test_skat_log = mt_test_skat_log.annotate_cols(non_refs = hl.agg.count_where(mt_test_skat_log.GT.is_non_ref())) #count variants per sample, prepare also test matrix\n",
    "            non_refs_test = mt_test_skat_log.non_refs.collect()\n",
    "\n",
    "            variants_gts[rows] = np.mean(np.array(non_refs)[categories])\n",
    "            variants_controls[rows] = np.mean(np.array(non_refs)[np.invert(categories)])\n",
    "\n",
    "            variants_gts_test[rows] = np.mean(np.array(non_refs_test)[categories_test])\n",
    "            variants_controls_test[rows] = np.mean(np.array(non_refs_test)[np.invert(categories_test)])\n",
    "\n",
    "            results = (non_refs - variants_controls[rows]) \n",
    "            results_test = (non_refs_test - variants_controls[rows]) \n",
    "\n",
    "            model_asignment[rows] = (results)\n",
    "            test_asignment[rows] = (results_test)\n",
    "\n",
    "        model_asignment = np.sum(model_asignment, axis = 0)\n",
    "        test_asignment = np.sum(test_asignment, axis = 0)\n",
    "            \n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-variants_gts'+str(s)+'cadd'+str(c), variants_gts)\n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-variants_controls'+str(s)+'cadd'+str(c), variants_controls)\n",
    "\n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-variants_gts_test'+str(s)+'cadd'+str(c), variants_gts_test)\n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-variants_controls_test'+str(s)+'cadd'+str(c), variants_controls_test)\n",
    "\n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-model_asignment'+str(s)+'cadd'+str(c), model_asignment)\n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-test_asignment'+str(s)+'cadd'+str(c), test_asignment)\n",
    "\n",
    "        false_pos = []\n",
    "        true_pos = []\n",
    "            \n",
    "        for x in np.linspace(-25,20,20000):\n",
    "            false_pos.append(np.sum((test_asignment > x)[np.invert(categories_test)])/56)\n",
    "            true_pos.append(np.sum((test_asignment > x)[categories_test])/89)\n",
    "                \n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-false_pos'+str(s)+'cadd'+str(c), false_pos)\n",
    "        np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-true_pos'+str(s)+'cadd'+str(c), true_pos)\n",
    "            \n",
    "        print(str(s)+'cadd'+str(c))\n",
    "        print(variants_gts)\n",
    "        print(variants_controls)\n",
    "\n",
    "false_pos = []\n",
    "true_pos = []\n",
    "\n",
    "for s in sets:\n",
    "        for c in cadds:\n",
    "            false_pos.append(np.load('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/results/numpy/may-false_pos'+str(s)+'cadd'+str(c)+'.npy'))\n",
    "            true_pos.append(np.load('/net/archive/groups/plggneuromol/imdik-zekanowski-gts/results/numpy/may-true_pos'+str(s)+'cadd'+str(c)+'.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.models import Label, LabelSet\n",
    "\n",
    "colors = bokeh.palettes.Category20[16]\n",
    "\n",
    "y = np.linspace(0,1,10)\n",
    "x = np.linspace(0,1,10)\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "output_notebook\n",
    "\n",
    "p = figure(plot_width=800, plot_height=800)\n",
    "p.line(x, y, line_width=4, line_color='lightgrey')\n",
    "\n",
    "for i in range(16):\n",
    "    p.line(false_pos[i], true_pos[i], line_width=1, alpha=0.5, line_color=colors[i])\n",
    "    \n",
    "p.line(false_pos[13], true_pos[13], line_width=4, line_color='orange')\n",
    "\n",
    "p.circle(false_pos[13][10740], true_pos[13][10740], size=12, color=\"darkred\", alpha=1)\n",
    "p.circle(false_pos[13][10760], true_pos[13][10760], size=12, color=\"red\", alpha=1)\n",
    "\n",
    "labels = LabelSet(x=[false_pos[13][10740], false_pos[13][10760]], y=[false_pos[13][10740], false_pos[13][10760]], text=['point A', 'point B'],\n",
    "              x_offset=5, y_offset=5, render_mode='canvas')\n",
    "\n",
    "p.add_layout(labels)\n",
    "\n",
    "\n",
    "p.xaxis.axis_label = 'false positives'\n",
    "p.yaxis.axis_label = 'true positives'\n",
    "\n",
    "p.xaxis.axis_label_text_font_size = \"15pt\"\n",
    "p.xaxis.major_label_text_font_size = \"15pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"15pt\"\n",
    "p.yaxis.major_label_text_font_size = \"15pt\"\n",
    "\n",
    "show(p)\n",
    "\n",
    "auc = []\n",
    "\n",
    "for i in range(16):\n",
    "    auc.append(-np.trapz(true_pos[i], false_pos[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(auc == max(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = []\n",
    "for s in sets:\n",
    "    for c in cadds:\n",
    "        factors.append(str(s)+'cadds:'+str(c))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the false positive rate of models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_background = mt_test.nearest_genes_20kb.collect()\n",
    "genes_background_1 =  set([val for sublist in genes_background for val in sublist])\n",
    "\n",
    "genes_background = [x for x in genes_background_1 if x in allgenes]\n",
    "\n",
    "genes_background = np.array(genes_background)\n",
    "np.save('genes_background', genes_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_background = np.load('/net/archive/groups/plggneuromol/GTS-analysis/analysis/numpy/genes_background.npy')\n",
    "\n",
    "sets = [2,3,4,5]\n",
    "cadds = [5,10,15,20]\n",
    "\n",
    "categories = mt_for_skat.category.collect()\n",
    "categories_test = mt_test.category.collect()\n",
    "\n",
    "mt_test = mt_test.filter_rows(mt_test.cadd > 5)\n",
    "mt_test = checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_test_5.mt')\n",
    "mt_test = mt_test.filter_rows(mt_test.cadd > 10)\n",
    "mt_test.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_test_10.mt')\n",
    "mt_test = mt_test.filter_rows(mt_test.cadd > 15)\n",
    "mt_test.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_test_15.mt')\n",
    "mt_test = mt_test.filter_rows(mt_test.cadd > 20)\n",
    "mt_test.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_test_20.mt')\n",
    "\n",
    "mt_for_skat = mt_for_skat.filter_rows(mt_for_skat.cadd > 5)\n",
    "mt_for_skat.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_for_skat_5.mt')\n",
    "mt_for_skat = mt_for_skat.filter_rows(mt_for_skat.cadd > 10)\n",
    "mt_for_skat.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_for_skat_10.mt')\n",
    "mt_for_skat = mt_for_skat.filter_rows(mt_for_skat.cadd > 15)\n",
    "mt_for_skat.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_for_skat_15.mt')\n",
    "mt_for_skat = mt_for_skat.filter_rows(mt_for_skat.cadd > 20)\n",
    "mt_for_skat.checkpoint('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_for_skat_20.mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in range(28,31):\n",
    "\n",
    "    randoms = np.random.randint(len(genes_background), size=5)\n",
    "    top_genes = [j for i, j in enumerate(genes_background) if i in randoms]\n",
    "\n",
    "    print(top_genes)\n",
    "        \n",
    "    for c_idx, c in enumerate(cadds):\n",
    "\n",
    "        test_asignment = np.zeros((len(top_genes), 145)) \n",
    "        mt_skat_log = hl.read_matrix_table('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_for_skat_'+str(c)+'.mt')\n",
    "        mt_test_skat_log = hl.read_matrix_table('/net/archive/groups/plggneuromol/GTS-analysis/data/mt_test_'+str(c)+'.mt')\n",
    "      \n",
    "        for rows, n in enumerate(top_genes):\n",
    "\n",
    "            mt_skat_log_gene = mt_skat_log.filter_rows(mt_skat_log.nearest_genes_20kb.contains(n)) # to ma gnomadów i heavy tics\n",
    "        \n",
    "            mt_test_skat_log_gene = mt_test_skat_log.filter_rows(mt_test_skat_log.nearest_genes_20kb.contains(n)) # to ma rodziny\n",
    "\n",
    "            mt_skat_log_gene = mt_skat_log_gene.annotate_cols(non_refs = hl.agg.count_where(mt_skat_log_gene.GT.is_non_ref())) #count variants per sample of gnomads and heavy tics  \n",
    "            non_refs = mt_skat_log_gene.non_refs.collect()\n",
    "                                                \n",
    "            mt_test_skat_log_gene = mt_test_skat_log_gene.annotate_cols(non_refs = hl.agg.count_where(mt_test_skat_log_gene.GT.is_non_ref())) #count variants per sample, prepare also test matrix\n",
    "            non_refs_test = mt_test_skat_log_gene.non_refs.collect()\n",
    "\n",
    "            variants_controls = np.mean(np.array(non_refs)[np.invert(categories)])\n",
    "                \n",
    "            test_asignment[rows] = (non_refs_test - variants_controls)\n",
    "            \n",
    "            print(test_asignment.shape)\n",
    "                \n",
    "        for s in sets:\n",
    "        \n",
    "            test_asignment_subset = test_asignment[range(5-s,5), :]\n",
    "            \n",
    "            print(test_asignment_subset.shape)\n",
    "                \n",
    "            test_asignment_subset = np.sum(test_asignment_subset, axis = 0)\n",
    "                \n",
    "            false_pos = []\n",
    "            true_pos = []\n",
    "            \n",
    "            for x in np.linspace(-100,100,10000):\n",
    "            \n",
    "                false_pos.append(np.sum((test_asignment_subset > x)[np.invert(categories_test)])/53)\n",
    "                true_pos.append(np.sum((test_asignment_subset > x)[categories_test])/91)\n",
    "            \n",
    "            print(np.trapz(false_pos, true_pos))\n",
    "        \n",
    "            np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/auc-test/false_pos'+str(s)+'cadd'+str(c)+'gene'+str(gene), false_pos)\n",
    "            np.save('/net/archive/groups/plggneuromol/GTS-analysis/data/auc-test/true_pos'+str(s)+'cadd'+str(c)+'gene'+str(gene), true_pos)\n",
    "        \n",
    "    print('I have completed iteration number: ' + str(gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = []\n",
    "true_pos = []\n",
    "\n",
    "for s in sets:\n",
    "    for c in cadds:\n",
    "        for gene in range(0,31):    \n",
    "            a = np.load('/net/archive/groups/plggneuromol/GTS-analysis/data/auc-test/false_pos'+str(s)+'cadd'+str(c)+'gene'+str(gene)+'.npy')\n",
    "            b = np.load('/net/archive/groups/plggneuromol/GTS-analysis/data/auc-test/true_pos'+str(s)+'cadd'+str(c)+'gene'+str(gene)+'.npy')\n",
    "            \n",
    "            a = a*53/56 #this is to correct the number of healthy\n",
    "            b = b*91/89 #this is to correct the number with GTS\n",
    "\n",
    "                \n",
    "            if (a[0] == 1) & (a[9999] == 0) & (b[0] == 1) & (b[9999] == 0):\n",
    "                false_pos.append(a)\n",
    "                true_pos.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aucs = []\n",
    "for i in range(478):\n",
    "    aucs.append(np.trapz(true_pos[i], false_pos[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = np.array(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(-aucs, 99.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.array(([0,1,2,4,5], [0,2,2,3,5]))\n",
    "test2 = np.array(([1,1,1,1,1], [2,2,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.linspace(0,1,10)\n",
    "x = np.linspace(0,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_ori = []\n",
    "true_pos_ori = []\n",
    "\n",
    "for s in sets:\n",
    "        for c in cadds:\n",
    "            false_pos_ori.append(np.load('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-false_pos'+str(s)+'cadd'+str(c)+'.npy'))\n",
    "            true_pos_ori.append(np.load('/net/archive/groups/plggneuromol/GTS-analysis/data/numpy/may-true_pos'+str(s)+'cadd'+str(c)+'.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = figure(plot_width=800, plot_height=800)\n",
    "p4.line(x, y, line_width=4, line_color='lightgrey')\n",
    "\n",
    "\n",
    "for i in range(0,296):\n",
    "    p4.line(false_pos[i], true_pos[i], line_width=1, alpha=0.25)\n",
    "    \n",
    "p4.line(false_pos_ori[13], true_pos_ori[13], line_width=4, line_color='orange')\n",
    "\n",
    "p4.xaxis.axis_label = 'false positives'\n",
    "p4.yaxis.axis_label = 'true positives'\n",
    "\n",
    "\n",
    "p4.xaxis.axis_label_text_font_size = \"15pt\"\n",
    "p4.xaxis.major_label_text_font_size = \"15pt\"\n",
    "p4.yaxis.axis_label_text_font_size = \"15pt\"\n",
    "p4.yaxis.major_label_text_font_size = \"15pt\"\n",
    "\n",
    "# show the results\n",
    "show(p4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
