{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8830a0a3-d54a-4da3-8b32-a33ae3bbdb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "localfs_path = os.environ.get('SCRATCH_LOCAL') + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4762a4-78b7-4788-aac0-b3510bd10a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/localfs/4138335/\n",
      "Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/localfs/4138335/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/30 07:18:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.3.2\n",
      "SparkUI available at http://ac0105:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.113-cf32652c5077\n",
      "LOGGING: writing to /net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/preprocessing/oligogenic-model/hail-20230730-0717-0.2.113-cf32652c5077.log\n"
     ]
    }
   ],
   "source": [
    "os.environ['_JAVA_OPTIONS'] = f'-Djava.io.tmpdir={localfs_path}'\n",
    "\n",
    "import hail as hl\n",
    "\n",
    "hl.init(\n",
    "    tmp_dir=(localfs_path+'tmp_hail'),\n",
    "    spark_conf={'spark.driver.memory': '30G', 'spark.executor.memory': '10G'}, # I don't know what should be here\n",
    "    default_reference='GRCh38'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf582ceb-8db7-456a-933f-137b8ccc157e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f5ef02-a85a-46eb-990c-cbf60c9ecd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_pca(mtx, mtx_path, suffix):\n",
    "    mtx = hl.variant_qc(mtx)\n",
    "    mtx = mtx.checkpoint(localfs_path+'variant_qced_'+suffix+mtx_path)\n",
    "    mtx = hl.read_matrix_table(localfs_path+'variant_qced_'+suffix+mtx_path)\n",
    "    for_pca = mtx.filter_rows(mtx.variant_qc.AF[1] > 0.05)\n",
    "    pruned_variant_table = hl.ld_prune(for_pca.GT, r2=0.2, bp_window_size=500000)\n",
    "    for_pca = for_pca.filter_rows(hl.is_defined(pruned_variant_table[for_pca.row_key]))\n",
    "\n",
    "    for_pca = for_pca.checkpoint(localfs_path+'for_pca_20_'+suffix+mtx_path)\n",
    "    for_pca = hl.read_matrix_table(localfs_path+'for_pca_20_'+suffix+mtx_path)\n",
    "    eigenvalues, pcs, _ = hl.hwe_normalized_pca(for_pca.GT, k=20)\n",
    "    \n",
    "    mtx = mtx.annotate_cols(pruned_scores = pcs[mtx.s].scores)\n",
    "    mtx = mtx.checkpoint(localfs_path+'after_pca_20_'+suffix+mtx_path)\n",
    "    \n",
    "    return(mtx)\n",
    "\n",
    "def run_pca_no_filter(mtx, mtx_path, suffix):\n",
    "    \n",
    "    for_pca = mtx.sample_rows(0.1)\n",
    "\n",
    "    for_pca = for_pca.checkpoint(localfs_path+'subset_'+suffix+mtx_path)\n",
    "    for_pca = hl.read_matrix_table(localfs_path+'subset_'+suffix+mtx_path)\n",
    "    eigenvalues, pcs, _ = hl.hwe_normalized_pca(for_pca.GT, k=20)\n",
    "    \n",
    "    mtx = mtx.annotate_cols(scores_no_filter = pcs[mtx.s].scores)\n",
    "    mtx = mtx.checkpoint(localfs_path+'after_pca_no_filters_'+suffix+mtx_path)\n",
    "    \n",
    "    return(mtx)\n",
    "\n",
    "def remove_pca_outliers(mtx, field, last_score, mtx_path, suffix):\n",
    "    \n",
    "    mtx = mtx.annotate_globals(\n",
    "            st = mtx.aggregate_cols(\n",
    "                hl.agg.array_agg(\n",
    "                    lambda pc: hl.agg.stats(pc),\n",
    "                    mtx[field])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    mtx = mtx.annotate_cols(\n",
    "            pc_outliers=hl.map(\n",
    "                lambda s, st: hl.int((s > st['mean'] + (10 * st['stdev'])) | (s < st['mean'] - (10 * st['stdev']))),\n",
    "                mtx[field][0:last_score],\n",
    "                mtx.st\n",
    "            )\n",
    "        )\n",
    "\n",
    "    mtx = mtx.filter_cols(\n",
    "        hl.sum(mtx.pc_outliers) ==  0\n",
    "    )\n",
    "    \n",
    "    mtx = mtx.checkpoint(localfs_path+'no_outliers'+mtx_path+suffix+'.mt')\n",
    "    \n",
    "    return(mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f0d1a-d46a-43bf-926b-013b768b1c6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### select matrices for skat:\n",
    "1. sportsmen vs GTS 40\n",
    "2. polish zeros vs GTS 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd17773a-d9ed-480d-859c-3732a81b4ae8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FatalError",
     "evalue": "HailException: No file or directory found at /localfs/4138335/poles_zerosunion.mt\n\nJava stack trace:\nis.hail.utils.HailException: No file or directory found at /localfs/4138335/poles_zerosunion.mt\n\tat is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17)\n\tat is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17)\n\tat is.hail.utils.package$.fatal(package.scala:78)\n\tat is.hail.expr.ir.RelationalSpec$.readMetadata(AbstractMatrixTableSpec.scala:33)\n\tat is.hail.expr.ir.RelationalSpec$.readReferences(AbstractMatrixTableSpec.scala:69)\n\tat is.hail.variant.ReferenceGenome$.fromHailDataset(ReferenceGenome.scala:560)\n\tat is.hail.backend.spark.SparkBackend.pyLoadReferencesFromDataset(SparkBackend.scala:618)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\n\n\nHail version: 0.2.113-cf32652c5077\nError summary: HailException: No file or directory found at /localfs/4138335/poles_zerosunion.mt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mt_1 \u001b[38;5;241m=\u001b[39m hl\u001b[38;5;241m.\u001b[39mread_matrix_table(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/gts_and_s.mt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m mt_2 \u001b[38;5;241m=\u001b[39m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_matrix_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocalfs_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoles_zerosunion.mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-1462>:2\u001b[0m, in \u001b[0;36mread_matrix_table\u001b[0;34m(path, _intervals, _filter_intervals, _drop_cols, _drop_rows, _create_row_uids, _create_col_uids, _n_partitions, _assert_type, _load_refs)\u001b[0m\n",
      "File \u001b[0;32m/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/venv-hail-0.2.113/lib/python3.10/site-packages/hail/typecheck/check.py:584\u001b[0m, in \u001b[0;36m_make_dec.<locals>.wrapper\u001b[0;34m(__original_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;129m@decorator\u001b[39m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(__original_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    583\u001b[0m     args_, kwargs_ \u001b[38;5;241m=\u001b[39m check_all(__original_func, args, kwargs, checkers, is_method\u001b[38;5;241m=\u001b[39mis_method)\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__original_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/venv-hail-0.2.113/lib/python3.10/site-packages/hail/methods/impex.py:2550\u001b[0m, in \u001b[0;36mread_matrix_table\u001b[0;34m(path, _intervals, _filter_intervals, _drop_cols, _drop_rows, _create_row_uids, _create_col_uids, _n_partitions, _assert_type, _load_refs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read in a :class:`.MatrixTable` written with :meth:`.MatrixTable.write`.\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m \n\u001b[1;32m   2540\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;124;03m:class:`.MatrixTable`\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _load_refs:\n\u001b[0;32m-> 2550\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rg_config \u001b[38;5;129;01min\u001b[39;00m \u001b[43mEnv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_references_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2551\u001b[0m         hl\u001b[38;5;241m.\u001b[39mReferenceGenome\u001b[38;5;241m.\u001b[39m_from_config(rg_config)\n\u001b[1;32m   2553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _intervals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _n_partitions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/venv-hail-0.2.113/lib/python3.10/site-packages/hail/backend/py4j_backend.py:118\u001b[0m, in \u001b[0;36mPy4JBackend.load_references_from_dataset\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_references_from_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyLoadReferencesFromDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/venv-hail-0.2.113/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/venv-hail-0.2.113/lib/python3.10/site-packages/hail/backend/py4j_backend.py:35\u001b[0m, in \u001b[0;36mhandle_java_exception.<locals>.deco\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     tpl \u001b[38;5;241m=\u001b[39m Env\u001b[38;5;241m.\u001b[39mjutils()\u001b[38;5;241m.\u001b[39mhandleForPython(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m     34\u001b[0m     deepest, full, error_id \u001b[38;5;241m=\u001b[39m tpl\u001b[38;5;241m.\u001b[39m_1(), tpl\u001b[38;5;241m.\u001b[39m_2(), tpl\u001b[38;5;241m.\u001b[39m_3()\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m fatal_error_from_java_error_triplet(deepest, full, error_id) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyspark\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mCapturedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FatalError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mJava stack trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHail version: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError summary: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39mdesc, e\u001b[38;5;241m.\u001b[39mstackTrace, hail\u001b[38;5;241m.\u001b[39m__version__, e\u001b[38;5;241m.\u001b[39mdesc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mFatalError\u001b[0m: HailException: No file or directory found at /localfs/4138335/poles_zerosunion.mt\n\nJava stack trace:\nis.hail.utils.HailException: No file or directory found at /localfs/4138335/poles_zerosunion.mt\n\tat is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17)\n\tat is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17)\n\tat is.hail.utils.package$.fatal(package.scala:78)\n\tat is.hail.expr.ir.RelationalSpec$.readMetadata(AbstractMatrixTableSpec.scala:33)\n\tat is.hail.expr.ir.RelationalSpec$.readReferences(AbstractMatrixTableSpec.scala:69)\n\tat is.hail.variant.ReferenceGenome$.fromHailDataset(ReferenceGenome.scala:560)\n\tat is.hail.backend.spark.SparkBackend.pyLoadReferencesFromDataset(SparkBackend.scala:618)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\n\n\nHail version: 0.2.113-cf32652c5077\nError summary: HailException: No file or directory found at /localfs/4138335/poles_zerosunion.mt"
     ]
    }
   ],
   "source": [
    "mt_1 = hl.read_matrix_table('/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/gts_and_s.mt')\n",
    "mt_2 = hl.read_matrix_table(localfs_path+'poles_zerosunion.mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde320f7-8e8d-4d74-9da8-674fc8cddff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mts = [mt_1, mt_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249791b1-a137-469e-b5d2-04963abb5422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 10:12:44.839 Hail: INFO: Reading table to impute column types\n",
      "2023-07-28 10:12:46.159 Hail: INFO: Finished type imputation\n",
      "  Loading field 'ID' as type str (imputed)\n",
      "  Loading field 'family' as type str (imputed)\n",
      "  Loading field 'sex' as type str (imputed)\n",
      "  Loading field 'kinship' as type str (imputed)\n",
      "  Loading field 'disease' as type str (imputed)\n",
      "  Loading field 'phenotype' as type str (imputed)\n",
      "  Loading field 'add_pheno' as type str (imputed)\n",
      "  Loading field 'heavy_tics' as type str (imputed)\n",
      "  Loading field 'heavy_tics_familial' as type str (imputed)\n",
      "  Loading field 'GTS_ASD_group' as type str (imputed)\n",
      "  Loading field 'nonCTD' as type str (imputed)\n"
     ]
    }
   ],
   "source": [
    "pheno = hl.import_table(\n",
    "    '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/pheno/GTS-coded-corrected-june-2021.csv',\n",
    "    impute=True,\n",
    "    delimiter=',',\n",
    "    quote=\"\\\"\"\n",
    ")\n",
    "\n",
    "pheno = pheno.key_by(pheno.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb443749-5991-40f6-86d8-a52a97f62234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, mt in enumerate(mts):\n",
    "    mt = mt.annotate_cols(\n",
    "    group = hl.if_else(\n",
    "            mt.s.contains('B'),\n",
    "            'local_controls',\n",
    "            hl.if_else(\n",
    "                (mt.s.contains('NA') | mt.s.contains('HG')),\n",
    "                '1kg_controls',\n",
    "                hl.if_else(\n",
    "                    mt.s.contains('polish'),\n",
    "                    'polish_controls',\n",
    "                    'GTS'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    mt = mt.annotate_cols(phenotypes = pheno[mt.s])\n",
    "    mts[idx] = mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cfa4a11-fdeb-43a7-8b03-6cd62e3f9fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 10:17:25.191 Hail: INFO: wrote matrix table with 4753663 rows and 142 columns in 4388 partitions to /localfs/4130551/s_vs_gts.mt\n",
      "2023-07-28 10:36:47.882 Hail: INFO: wrote matrix table with 3035372 rows and 1240 columns in 4389 partitions to /localfs/4130551/pw_vs_gts.mt\n"
     ]
    }
   ],
   "source": [
    "#sportsmen vs GTS 40\n",
    "s_vs_gts = mts[0].filter_cols((mts[0].group == 'local_controls') | (mts[0].phenotypes.family == '.'))\n",
    "s_vs_gts = s_vs_gts.filter_rows(hl.agg.any(s_vs_gts.GT.is_non_ref()))\n",
    "s_vs_gts = s_vs_gts.checkpoint(localfs_path+'s_vs_gts.mt')    \n",
    "\n",
    "# polish no zeros vs GTS 40\n",
    "pw_vs_gts = mts[1].filter_cols((mts[1].group == 'polish_controls') | (mts[1].phenotypes.family == '.'))\n",
    "pw_vs_gts = pw_vs_gts.filter_rows(hl.agg.any(pw_vs_gts.GT.is_non_ref()))\n",
    "pw_vs_gts = pw_vs_gts.checkpoint(localfs_path+'pw_vs_gts.mt') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f21b243-52cc-458a-b525-c3327fac59c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_vs_gts = hl.read_matrix_table(localfs_path+'s_vs_gts.mt')  \n",
    "pw_vs_gts = hl.read_matrix_table(localfs_path+'pw_vs_gts.mt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107312e7-1db9-41c5-ac9c-12e1cd691b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_vs_gts = s_vs_gts.naive_coalesce(500)\n",
    "pw_vs_gts = pw_vs_gts.naive_coalesce(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f436aa0-8625-4421-b51b-443fbdce7210",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_vs_gts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s_vs_gts \u001b[38;5;241m=\u001b[39m \u001b[43ms_vs_gts\u001b[49m\u001b[38;5;241m.\u001b[39mcheckpoint(localfs_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms_vs_gts_rep.mt\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 's_vs_gts' is not defined"
     ]
    }
   ],
   "source": [
    "s_vs_gts = s_vs_gts.checkpoint(localfs_path+'s_vs_gts_rep.mt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521856ed-54d8-4b5c-b973-22becff9a1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 16:39:07.547 Hail: INFO: wrote matrix table with 3035372 rows and 1240 columns in 488 partitions to /localfs/4130551/pw_vs_gts_rep.mt\n"
     ]
    }
   ],
   "source": [
    "pw_vs_gts = pw_vs_gts.checkpoint(localfs_path+'pw_vs_gts_rep.mt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d565d33e-67c4-495c-b46a-8b27588930cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_vs_gts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     \u001b[43ms_vs_gts\u001b[49m,\n\u001b[1;32m      3\u001b[0m     pw_vs_gts\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m mts_2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     s_vs_gts,\n\u001b[1;32m      7\u001b[0m     pw_vs_gts\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m mts_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms_vs_gts\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpw_vs_gts\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 's_vs_gts' is not defined"
     ]
    }
   ],
   "source": [
    "mts = [\n",
    "    s_vs_gts,\n",
    "    pw_vs_gts\n",
    "]\n",
    "mts_2 = [\n",
    "    s_vs_gts,\n",
    "    pw_vs_gts\n",
    "]\n",
    "mts_paths = [\n",
    "    's_vs_gts',\n",
    "    'pw_vs_gts'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20be30f-0680-4d15-8aee-5b99cb591dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, mt in enumerate(mts):\n",
    "    mts[idx] = run_pca(mt, mts_paths[idx], 'three_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790e5f5-2b86-460c-9173-f1a35069ef43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mts_paths = [\n",
    "    's_vs_gts',\n",
    "    'pw_vs_gts'\n",
    "]\n",
    "\n",
    "for mt_path in mts_paths:\n",
    "    mt = hl.read_matrix_table(localfs_path+'after_pca_20_three_'+mt_path)\n",
    "    mt.write(\n",
    "        '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/redone_after_pca_20_'+mt_path+'.mt',\n",
    "        overwrite = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f04f87-ea97-4e13-90a7-641e3d7299ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mts_paths = [\n",
    "    's_vs_gts',\n",
    "    'pw_vs_gts'\n",
    "]\n",
    "\n",
    "mts = []\n",
    "\n",
    "for mt_path in mts_paths:\n",
    "    mt = hl.read_matrix_table(\n",
    "        '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/redone_after_pca_20_'+mt_path+'.mt'\n",
    "    )\n",
    "    \n",
    "    mts.append(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5302ee7d-b0bb-4141-8895-b6787eba4b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 06:57:24.333 Hail: INFO: wrote matrix table with 474526 rows and 142 columns in 488 partitions to /localfs/4138335/subset_ones_vs_gts\n",
      "    Total size: 3.15 GiB\n",
      "    * Rows/entries: 3.15 GiB\n",
      "    * Columns: 39.82 KiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 0 rows (20.00 B)\n",
      "    * Largest partition:  2425 rows (18.28 MiB)\n",
      "2023-07-30 06:58:07.695 Hail: INFO: hwe_normalize: found 469968 variants after filtering out monomorphic sites.\n",
      "2023-07-30 06:58:12.298 Hail: INFO: pca: running PCA with 20 components.../ 488]\n",
      "2023-07-30 06:58:44.977 Hail: INFO: wrote table with 0 rows in 0 partitions to /localfs/4138335/tmp_hail/persist_table4LCyw0UDZ7\n",
      "    Total size: 23.24 KiB\n",
      "    * Rows: 0.00 B\n",
      "    * Globals: 23.24 KiB\n",
      "    * Smallest partition: N/A\n",
      "    * Largest partition:  N/A\n",
      "2023-07-30 07:00:07.504 Hail: INFO: wrote matrix table with 4753663 rows and 142 columns in 488 partitions to /localfs/4138335/after_pca_no_filters_ones_vs_gts\n",
      "2023-07-30 07:01:13.752 Hail: INFO: wrote matrix table with 304885 rows and 1240 columns in 488 partitions to /localfs/4138335/subset_onepw_vs_gts\n",
      "    Total size: 2.64 GiB\n",
      "    * Rows/entries: 2.64 GiB\n",
      "    * Columns: 203.86 KiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 0 rows (20.00 B)\n",
      "    * Largest partition:  1751 rows (15.62 MiB)\n",
      "2023-07-30 07:01:18.071 Hail: INFO: hwe_normalize: found 301090 variants after filtering out monomorphic sites.\n",
      "2023-07-30 07:01:22.694 Hail: INFO: pca: running PCA with 20 components.../ 488]\n",
      "2023-07-30 07:02:05.548 Hail: INFO: wrote table with 0 rows in 0 partitions to /localfs/4138335/tmp_hail/persist_tablekZvgmJaASJ\n",
      "    Total size: 202.92 KiB\n",
      "    * Rows: 0.00 B\n",
      "    * Globals: 202.92 KiB\n",
      "    * Smallest partition: N/A\n",
      "    * Largest partition:  N/A\n",
      "2023-07-30 07:03:32.314 Hail: INFO: wrote matrix table with 3035372 rows and 1240 columns in 488 partitions to /localfs/4138335/after_pca_no_filters_onepw_vs_gts\n"
     ]
    }
   ],
   "source": [
    "mts_2 = []\n",
    "\n",
    "for idx, mt in enumerate(mts):\n",
    "     mts_2.append(run_pca_no_filter(mt, mts_paths[idx], 'one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe2afb6-078f-4a84-8a74-23a65f434606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mts_paths = [\n",
    "    's_vs_gts',\n",
    "    'pw_vs_gts'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c55840-013e-4ae9-94c2-ed9b113d2973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mts = []\n",
    "\n",
    "for mt_path in mts_paths:\n",
    "    mt = hl.read_matrix_table(localfs_path+'after_pca_no_filters_one'+mt_path)\n",
    "    mts.append(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bbed3fb-4192-470b-9e08-e3d6aba138d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts_2 = []\n",
    "\n",
    "for mt_path in mts_paths:\n",
    "    \n",
    "    mt = hl.read_matrix_table(\n",
    "        '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/redone_after_pca_20_'+mt_path+'.mt'\n",
    "    ) \n",
    "    \n",
    "    mts_2.append(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0e23d-682d-4405-b457-0f9ab2c173ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 07:32:53.296 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "[Stage 0:================================>                     (291 + 12) / 488]\r"
     ]
    }
   ],
   "source": [
    "for idx, mt in enumerate(mts):\n",
    "    \n",
    "    mt = mt.annotate_cols(pruned_scores = mts_2[idx].cols()[mt.s].pruned_scores) #these are the pruned scores\n",
    "    \n",
    "    mt.write(\n",
    "        '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/'+mts_paths[idx]+'_pca.mt',\n",
    "        overwrite = True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44cc21f5-be58-40a1-a6ad-a03c8a35e767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mts_paths = [\n",
    "    's_vs_gts',\n",
    "    'pw_vs_gts'\n",
    "]\n",
    "\n",
    "mts = []\n",
    "\n",
    "for path in mts_paths:\n",
    "\n",
    "    mt = hl.read_matrix_table(\n",
    "        '/net/pr2/projects/plgrid/plggneuromol/imdik-zekanowski-gts/data/mts/oligogenic-model/'+path+'_pca.mt'\n",
    "    )\n",
    "    \n",
    "    mts.append(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4839edfd-b3dc-4519-a32c-51d649b44053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 08:45:45.318 Hail: INFO: wrote matrix table with 4753663 rows and 140 columns in 488 partitions to /localfs/4138335/no_outlierss_vs_gts_no_outs_pruned_2.mt\n",
      "2023-07-30 08:47:34.990 Hail: INFO: wrote matrix table with 4753663 rows and 140 columns in 488 partitions to /localfs/4138335/no_outlierss_vs_gts_no_outs_subs_2.mt\n",
      "2023-07-30 08:49:04.607 Hail: INFO: wrote matrix table with 3035372 rows and 1238 columns in 488 partitions to /localfs/4138335/no_outlierspw_vs_gts_no_outs_pruned_2.mt\n",
      "2023-07-30 08:50:32.847 Hail: INFO: wrote matrix table with 3035372 rows and 1238 columns in 488 partitions to /localfs/4138335/no_outlierspw_vs_gts_no_outs_subs_2.mt\n"
     ]
    }
   ],
   "source": [
    "# remove PCA outliers\n",
    "\n",
    "mtx_s_2 = []\n",
    "\n",
    "for idx, mt in enumerate(mts):\n",
    "    \n",
    "    mtx = remove_pca_outliers(mt, 'pruned_scores', 2, mts_paths[idx], '_no_outs_pruned_2')\n",
    "    mtx_2 = remove_pca_outliers(mt, 'scores_no_filter', 2, mts_paths[idx], '_no_outs_subs_2')\n",
    "    \n",
    "    mtx = mtx.drop(\n",
    "        mtx['scores_no_filter'],\n",
    "        mtx['pruned_scores']\n",
    "    )\n",
    "    \n",
    "    mtx_2 = mtx_2.drop(\n",
    "        mtx_2['scores_no_filter'],\n",
    "        mtx_2['pruned_scores']\n",
    "    )\n",
    "    \n",
    "    mts[idx] = mtx \n",
    "    mtx_s_2.append(mtx_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8470a04e-caae-4bb5-83c9-a054a8ac0067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4753663, 140)\n",
      "(3035372, 1238)\n"
     ]
    }
   ],
   "source": [
    "for mt in mts:\n",
    "    print(mt.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4187ca66-7ffa-49bf-9013-4af2cff1fb98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4753663, 140)\n",
      "(3035372, 1238)\n"
     ]
    }
   ],
   "source": [
    "for mtx in mtx_s_2:\n",
    "    print(mtx.count()) # the method makes no difference, always just two GTS samples are excluded. Which?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd880d71-4b5d-4d61-bf3d-33791806a7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mt_og = hl.read_matrix_table(localfs_path+'after_pca_no_filters_onepw_vs_gts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b44c0d2c-6276-41f8-bf17-c0edb39a5101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "og_samples = mt_og.filter_cols(mt_og.group == 'GTS').s.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd0e33a1-130e-4e0d-b9da-1b874c4d2cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_keep = mts[1].filter_cols(mts[1].group == 'GTS').s.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a3ea75-3fe7-4929-b5c9-7174eb01be26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WGS_5', 'WGS_8']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(og_samples).difference(to_keep)) # thease are two more samples to exclude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
