{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/site-packages (3.0.2)\r\n",
      "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/site-packages (from openpyxl) (1.4.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/site-packages (from openpyxl) (1.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel :)\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "\n",
    "# This line will hide code by default when the notebook is exported as HTML\n",
    "# di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = !ls 'sum'*'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sum_adhd.csv',\n",
       " 'sum_agg_beh.csv',\n",
       " 'sum_bg.csv',\n",
       " 'sum_echolalia.csv',\n",
       " 'sum_gts_genes.csv',\n",
       " 'sum_inv_mov.csv',\n",
       " 'sum_neuro_dev.csv',\n",
       " 'sum_ocd_beh.csv',\n",
       " 'sum_patho.csv',\n",
       " 'sum_self_mut.csv',\n",
       " 'sum_tics.csv']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dataframes = []\n",
    "\n",
    "for f in csv_list:\n",
    "    dfs.append(pd.read_csv(f))\n",
    "    dataframes.append(pd.read_csv(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a script to open .csv generated by imdik-zekanowski-gts, to remove some characters, split SnipEff annotations and make an excel file with separate sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, df in enumerate(dfs):\n",
    "    \n",
    "    df.replace({'\\[|\\]|\\'':''}, regex = True, inplace = True) \n",
    "    df.replace({'\\|':' '}, regex = True, inplace = True)  \n",
    "    df.replace({'\\^':' '}, regex = True,inplace = True)\n",
    "   \n",
    "    dataframes[idx] = df.SnpEff.str.split(\" \", expand=True)\n",
    "    dataframes[idx] = dataframes[idx].iloc[:, [1,2,7,10]]\n",
    "    dataframes[idx].columns = ['variant_type','impact','location','AA']\n",
    "    \n",
    "    df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "    df.drop(df.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "    dfs[idx] = pd.concat([df, dataframes[idx]], axis=1)\n",
    "    \n",
    "    d = dfs[0:(len(dfs)-1)]\n",
    "    d = pd.concat(d)\n",
    "    d = d[['sample','locus', 'genotype', 'alleles', 'family', 'sex', 'additional_pheno', 'Gene', 'impact']]\n",
    "    d.sort_values(['family', 'sample'], axis=0, inplace=True, ascending=True)\n",
    "    \n",
    "dfs.append(pd.read_csv('GTS-coded.csv'))\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('rare_patients_only.xlsx') as writer:\n",
    "    for idx, df in enumerate(dfs):\n",
    "        try:\n",
    "            df.to_excel(writer, sheet_name=str(csv_list[idx]))\n",
    "        except IndexError:\n",
    "            df.to_excel(writer, sheet_name='GTS-coded')\n",
    "    d.to_excel(writer, sheet_name='sample_centric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on variants that occur > 1\n",
    "df2 = pd.read_csv('high_double_all_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRPF3']      78\n",
       "['RAI1']       60\n",
       "['TP53']       38\n",
       "['GP1BA']      23\n",
       "['TRPV3']      18\n",
       "['ENTPD1']     16\n",
       "['PCK1']       12\n",
       "['TNK1']       10\n",
       "['PRKRA']       7\n",
       "['SCN4A']       7\n",
       "['IDH2']        6\n",
       "['HSPA9']       6\n",
       "['TBP']         4\n",
       "['HTT']         4\n",
       "['TBCD']        4\n",
       "['NDUFS7']      4\n",
       "['GGT1']        4\n",
       "['MTMR2']       3\n",
       "['GMPPB']       3\n",
       "['DMPK']        2\n",
       "['CIC']         2\n",
       "['FMO5']        2\n",
       "['EEF2']        2\n",
       "['SYNGAP1']     2\n",
       "['CCDC40']      2\n",
       "Name: Gene, dtype: int64"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find variants that occur in many many controls\n",
    "df2[df2['disease'] != 'YES']['Gene'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.replace({'\\[|\\]|\\'':''}, regex = True, inplace = True) \n",
    "df2.replace({'\\|':' '}, regex = True, inplace = True)  \n",
    "df2.replace({'\\^':' '}, regex = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[~df2['Gene'].isin(['PRPF3','RAI1','TP53','GP1BA','TRPV3','ENTPD1','PCK1','TNK1','PRKRA','SCN4A', 'IDH2', 'HSPA9','PAH'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['disease'] != 'NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.SnpEff.str.split(\" \", expand=True)\n",
    "df = df.iloc[:, [1,2,7,10]]\n",
    "df.columns = ['variant_type','impact','location','AA']\n",
    "\n",
    "df2.drop(df2.columns[len(df2.columns)-1], axis=1, inplace=True)\n",
    "df2.drop(df2.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "df2 = pd.concat([df2, df], axis=1)\n",
    "df2.sort_values(['family', 'sample'], axis=0, inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('doubles_patients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a script to open pickled objects, split some columns and create files for each family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = !ls ./py_objects/cols*\n",
    "rows = !ls ./py_objects/rows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "tables = []\n",
    "\n",
    "for col, row in zip(cols, rows):\n",
    "    info.append(pd.read_pickle(col))\n",
    "    tables.append(pd.read_pickle(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for idx, table in enumerate(tables):\n",
    "    \n",
    "    a = list(table.columns)\n",
    "\n",
    "    b = [x for x in a if 'phased' not in x]\n",
    "    b = [x for x in b if 'GQ' not in x]\n",
    "    c = [x for x in b if 'ISEQ' in x]\n",
    "    b = [x for x in b if 'ISEQ' not in x]\n",
    "    b.remove('ANN')\n",
    "    b.remove('PhastCons100way')\n",
    "    d = b + c\n",
    "    d.append('PhastCons100way')\n",
    "    d.append('ANN')\n",
    "    \n",
    "    table = table[d]\n",
    "    table = table.astype(str)\n",
    "    \n",
    "    table.replace({'\\[|\\]|\\'':''}, regex = True, inplace = True) \n",
    "    table.replace({'\\|':' '}, regex = True, inplace = True)  \n",
    "    table.replace({'\\^':' '}, regex = True,inplace = True)\n",
    "    \n",
    "    ann = table['ANN']\n",
    "    ann = ann.str.split(\" \", expand=True)\n",
    "    ann = ann.iloc[:, [1,2,7,10]]\n",
    "    ann.columns = ['variant_type','impact','location','AA']\n",
    "    \n",
    "    table.drop('ANN', axis=1, inplace=True)\n",
    "    table = pd.concat([table, ann], axis=1)\n",
    "    \n",
    "    tables[idx] = table\n",
    "    \n",
    "    e = pd.DataFrame(table.columns).transpose()\n",
    "    e.columns = table.columns\n",
    "    f = pd.concat([e, table], axis=0)\n",
    "\n",
    "    g = info[idx].transpose()\n",
    "    h = pd.DataFrame(g.index)\n",
    "    h.index = g.index\n",
    "    i = pd.concat([h, g], axis = 1)\n",
    "\n",
    "    i.columns = range(0,len(i.columns))\n",
    "    i = i.reindex(columns = ['a']*3 + list(range(0,len(i.columns))) + ['a']*13)\n",
    "\n",
    "    i.columns = f.columns\n",
    "    i.index = range(0,len(i.index))\n",
    "\n",
    "    f.index = range(len(i.index)+1,len(i.index)+len(f.index)+1)\n",
    "\n",
    "    j = pd.concat([i, f], axis = 0)\n",
    "    j.columns = range(0, len(j.columns))\n",
    "\n",
    "    results.append(j)\n",
    "\n",
    "    \n",
    "    \n",
    "with pd.ExcelWriter('families.xlsx') as writer:\n",
    "    for idx, res in enumerate(results):\n",
    "        res.to_excel(writer, sheet_name=str(res.iloc[1][4]), header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
